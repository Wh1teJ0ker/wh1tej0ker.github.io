<!doctype html><html lang=en><head><meta name=viewport content="width=device-width,initial-scale=1"><title>Wh1teJ0kerのBlog</title>
<meta charset=utf-8><meta name=description content="Ladder@一些关于CTF的AI安全学习"><meta name=author content="Wh1teJ0ker"><link rel=canonical href=https://wh1tej0ker.github.io/post/white-box-test-and-black-box-test-of-model-z9aye3.html><link rel=alternate type=application/rss+xml href=https://wh1tej0ker.github.io//index.xml title=Wh1teJ0kerのBlog><script async defer data-website-id=56cc42c1-3656-4d3e-af3c-acded927b8ed src=https://analytics.umami.is/script.js></script><meta property="og:url" content="https://wh1tej0ker.github.io/post/white-box-test-and-black-box-test-of-model-z9aye3.html"><meta property="og:site_name" content="Wh1teJ0kerのBlog"><meta property="og:title" content="模型的白盒测试和黑盒测试"><meta property="og:description" content="一些关于CTF的AI安全学习"><meta property="og:locale" content="zh_CN"><meta property="og:type" content="article"><meta property="article:section" content="post"><meta property="article:published_time" content="2024-08-23T21:38:09+08:00"><meta property="article:modified_time" content="2025-05-07T20:23:41+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="模型的白盒测试和黑盒测试"><meta name=twitter:description content="一些关于CTF的AI安全学习"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://wh1tej0ker.github.io/post/"},{"@type":"ListItem","position":2,"name":"模型的白盒测试和黑盒测试","item":"https://wh1tej0ker.github.io/post/white-box-test-and-black-box-test-of-model-z9aye3.html"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"模型的白盒测试和黑盒测试","name":"模型的白盒测试和黑盒测试","description":"一些关于CTF的AI安全学习","keywords":[],"articleBody":"一些关于CTF的AI安全学习\n模型的白盒测试和黑盒测试 黑盒测试-模型结构的推测与补全 首先在仅给模型文件的情况下，我们需要通过其他方式，将常见的一些模型进行推测出来。这边通过两道例题演示相关方法。\n我们需要先知道如何去读取Pth模型文件，探求模型的参数结构。\n‍ 1 2 3 4 5 import torch #自行选用cpu或者gpu pt = torch.load(\"./model.pth\", map_location=\"cpu\") for i in pt: print(i,pt[i].shape) 2.可视化的开源工具\nhttps://github.com/lutzroeder/netron\n这边我们选用两道题目作为实例，一个经典的手写LeNet模型，选自2023香山杯\n，一个是L3HCTF2021-DeepDarkFantasy，使用动态调试的方法逆向\n2024香山杯-LeNet 题目所给出的文件有以下：\nlabel.json MyLeNet.pt flag(使用npy格式存储) 先读取模型参数推测\n1 2 3 4 5 6 7 8 9 10 conv1.weight torch.Size([6, 1, 5, 5]) conv1.bias torch.Size([6]) conv2.weight torch.Size([16, 6, 5, 5]) conv2.bias torch.Size([16]) fc1.weight torch.Size([120, 256]) fc1.bias torch.Size([120]) fc2.weight torch.Size([84, 120]) fc2.bias torch.Size([84]) fc3.weight torch.Size([62, 84]) fc3.bias torch.Size([62]) ​​\n并且呢，我们再将npy进行可视化一下，明显是手写数字+字母\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 import numpy as np import matplotlib.pyplot as plt rows = 7 # 7行 cols = 8 # 8列 fig, axes = plt.subplots(rows, cols, figsize=(20, 20)) for i in range(56): depthmap = np.load(f'./flag/{i}.npy') # 使用numpy载入npy文件 ax = axes[i // cols, i % cols] # 确定当前子图位置 im = ax.imshow(depthmap, cmap='viridis') ax.set_title(f' {i}') # ax.axis('off') fig.colorbar(im, ax=axes, orientation='vertical', fraction=0.02, pad=0.04) plt.tight_layout() plt.savefig('./pic/all.jpg') plt.show() ​​\n这边是给出了相关两个方式都可以查看出存在两个卷积层和三个全连接层，并且给出了其中的基本参数，我们需要去对比一下跟标准的LeNet模型有什么区别，或者说还缺少什么。\n​​\n我们发现在经典的LeNet模型，可以发现每次卷积后会进行池化，此处池化我们进行简单化考虑，采用最大池化，因此重点是考虑关于激活函数的问题。\n（PS：实际在LeNet网络中，通常使用Sigmoid或Tanh激活函数在全连接层中，而在卷积层中可能使用Sigmoid、Tanh、ReLU等）\n我们这里通过实际对模型的逆向查看，发现存在的仅有ReLU函数和Sigmoid函数（PS：如何逆向，010硬看，能搜索到）\n需要使用到激活函数的一共有四个位置，卷积层或者全连接层的连接处，上面说明了一共两个卷积层，三个全连接层，因此需要使用到的是四个激活函数，卷积层需要搭配池化。\n因此最终的可能性一共在为16种情况。\n此外，还要注意在识别后需要对标签进行映射得到最终的FLAG\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 import torch import torch.nn as nn import json import numpy as np pt = torch.load(\"./MyLeNet.pt\", map_location=\"cpu\") class LeNet(nn.Module): def __init__(self): super(LeNet, self).__init__() self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1) self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2) self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1) self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2) self.fc1 = nn.Linear(256, 120) self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 62) def forward(self, x): x = self.conv1(x) x = self.maxpool1(x) x = nn.Sigmoid()(x) x = self.conv2(x) x = self.maxpool2(x) x = nn.ReLU()(x) x = torch.flatten(x, start_dim=1) x = self.fc1(x) x = nn.Sigmoid()(x) x = self.fc2(x) x = nn.ReLU()(x) x = self.fc3(x) return x # 创建LeNet实例 lenet_model = LeNet() lenet_model.load_state_dict(pt) with open('./label.json', 'r') as json_file: label_mapping = json.load(json_file) reverse_label_mapping = {v: k for k, v in label_mapping.items()} # 获取所有标签 chars = list(reverse_label_mapping.values()) predicted_chars = [] # 用于保存所有的预测字符 for i in range(56): # 从0到56 npy_file_path = f\"./flag/{i}.npy\" npy_data = np.load(npy_file_path).reshape((1, 1, 28, 28)) torch_input = torch.tensor(npy_data).float() # 转换为PyTorch张量 # 使用LeNet模型进行推理 output = lenet_model(torch_input) predicted_index = torch.argmax(output, dim=1).item() predicted_char = chars[predicted_index] print(f\"Prediction for {npy_file_path}: {predicted_char}\") predicted_chars.append(predicted_char) result_string = ''.join(predicted_chars) print(\"Concatenated Result:\", result_string) 2021L3HCTF-DeepDarkFantasy 直接打开encrypted.pth\n先进行异或，KEY为0xde\n​​\n使用调试的方法逐步补全模型\n​​\n白盒测试-模型的逆向工程 纯粹的模型逆向，先来分析一下初始代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 import torch import torch.nn as nn flag='' flag_list=[] for i in flag: flag_list.append(ord(i)) input=torch.tensor(flag_list, dtype=torch.float32) n=len(input) class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.linear = nn.Linear(n, n*n) self.conv=nn.Conv2d(1, 1, (2, 2), stride=1,padding=1) def forward(self, x): x = self.linear(x) x = x.view(1, 1, n, n) x=self.conv(x) return x mynet=Net() mynet.load_state_dict(torch.load('model.pth')) output=mynet(input) with open('ciphertext.txt', 'w') as f: for tensor in output: for channel in tensor: for row in channel: f.write(' '.join(map(str, row.tolist()))) f.write('\\n') 将字符串转换为ascii码后化为向量，利用一个神经网络，主要是包含全连接层和卷积层，将向量输出。\n关于这个网络，我们打印出模型数据，详细过程如下：\n1 2 3 4 5 6 7 8 9 import torch pt = torch.load(\"./model.pth\", map_location=\"cpu\") for i in pt: print(i,pt[i].shape) #linear.weight torch.Size([2209, 47]) #linear.bias torch.Size([2209]) #conv.weight torch.Size([1, 1, 2, 2]) #conv.bias torch.Size([1]) 输入处理： 输入是一个长度为 47​ 的向量。 通过线性层变换为一个长度为 2209​ 的向量。 重塑张量： 将长度为 2209​ 的向量重塑为 [1, 1, 47, 47]​ 的四维张量。 卷积操作： 卷积层应用一个 2x2​ 的卷积核，保持输出形状为 [1, 1, 47, 47]​。 同时，我们看到这里存在有n的未知参数，上述我们已经通过读取模型方式获取到n的初始值为47\n因此本题的重点也就是放在卷积层和全连接层的逆向操作\n卷积层的逆向取决于nn.Conv2d的操作，核心思想是将外围补零后进行逆向操作\nOther 其他的就是一些对抗生成模型，算是一个非常热门的考点，或者一些基于论文的AI模型安全问题，目前来说，这个方向资料相对比较少，也没有一个成熟的体系化建设，更多的需要继续去发掘。\n","wordCount":"1742","inLanguage":"en","datePublished":"2024-08-23T21:38:09+08:00","dateModified":"2025-05-07T20:23:41+08:00","author":{"@type":"Person","name":"Wh1teJ0ker"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://wh1tej0ker.github.io/post/white-box-test-and-black-box-test-of-model-z9aye3.html"},"publisher":{"@type":"Organization","name":"Wh1teJ0kerのBlog","logo":{"@type":"ImageObject","url":"https://wh1tej0ker.github.io/favicon.ico"}}}</script><link rel=icon type=image/png href=/favicon.ico sizes=16x16><link rel=apple-touch-icon href=/favicon.ico><link rel=manifest href=/favicon.ico><link rel=stylesheet href=https://cdn.staticfile.org/lxgw-wenkai-webfont/1.6.0/style.css><link rel=stylesheet href=/css/main.min.9d998bab4720091d5ec1e0fbbffd92b254a2e791623df6106cd7ea760bfc5c28.css integrity="sha256-nZmLq0cgCR1eweD7v/2SslSi55FiPfYQbNfqdgv8XCg=" crossorigin=anonymous media=screen><link rel=stylesheet href=/scss/highlight/github-dark.min.min.66034289ee9a113219a2c4aae0a8bd2095ab255c832a42efcf5863f10814e7a1.css><script src=/js/highlight.min.min.c607d6febd16934a82eb61d3a896ed9d869f54373cc63ce95864ed5488fe3128.js></script><script>hljs.highlightAll()</script></head><body><main class=wrapper><nav class=navigation><section class=container><a class=navigation-brand href=/>HOME
</a><input type=checkbox id=menu-toggle>
<label class="menu-button float-right" for=menu-toggle><span></span><span></span><span></span></label><ul class=navigation-list id=navigation-list><li class="navigation-item navigation-menu"><a class=navigation-link href=/categories/>分类</a></li><li class="navigation-item navigation-menu"><a class=navigation-link href=/archives/>归档</a></li><li class="navigation-item navigation-menu"><a class=navigation-link href=/friends/>友链</a></li><li class="navigation-item navigation-menu"><a class=navigation-link href=/about/>关于</a></li><li class="navigation-item navigation-menu"><a class=navigation-link href=https://cloud.umami.is/share/5RZUCwaG2fOysYPa/wh1tej0ker.github.io>Dashboard</a></li><li class="navigation-item menu-separator"><span>|</span></li><li class="navigation-item navigation-social"><a class=navigation-link href=https://github.com/Wh1teJ0ker><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-github"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a></li></ul></section></nav><div id=content><article class=blog-single><header class=blog-title><h1>模型的白盒测试和黑盒测试</h1></header><p><small>August 23, 2024&nbsp;· &nbsp;·</small><p><div class=blog-toc><nav id=TableOfContents><ul><li><a href=#2024香山杯-lenet>2024香山杯-LeNet</a></li><li><a href=#2021l3hctf-deepdarkfantasy>2021L3HCTF-DeepDarkFantasy</a></li></ul></nav></div><section class=blog-content><p>一些关于CTF的AI安全学习</p><h1 id=模型的白盒测试和黑盒测试>模型的白盒测试和黑盒测试</h1><h1 id=黑盒测试-模型结构的推测与补全>黑盒测试-模型结构的推测与补全</h1><p>首先在仅给模型文件的情况下，我们需要通过其他方式，将常见的一些模型进行推测出来。这边通过两道例题演示相关方法。</p><p>我们需要先知道如何去读取Pth模型文件，探求模型的参数结构。</p><ol><li>‍</li></ol><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=c1>#自行选用cpu或者gpu</span>
</span></span><span class=line><span class=cl><span class=n>pt</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=s2>&#34;./model.pth&#34;</span><span class=p>,</span> <span class=n>map_location</span><span class=o>=</span><span class=s2>&#34;cpu&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=n>pt</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>i</span><span class=p>,</span><span class=n>pt</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>2.可视化的开源工具</p><p><a href="https://github.com/lutzroeder/netron?tab=readme-ov-file">https://github.com/lutzroeder/netron</a></p><p>这边我们选用两道题目作为实例，一个经典的手写LeNet模型，选自2023香山杯</p><p>，一个是L3HCTF2021-DeepDarkFantasy，使用动态调试的方法逆向</p><h2 id=2024香山杯-lenet>2024香山杯-LeNet</h2><p>题目所给出的文件有以下：</p><ul><li>label.json</li><li>MyLeNet.pt</li><li>flag(使用npy格式存储)</li></ul><p>先读取模型参数推测</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>conv1</span><span class=o>.</span><span class=n>weight</span> <span class=n>torch</span><span class=o>.</span><span class=n>Size</span><span class=p>([</span><span class=mi>6</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>5</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=n>conv1</span><span class=o>.</span><span class=n>bias</span> <span class=n>torch</span><span class=o>.</span><span class=n>Size</span><span class=p>([</span><span class=mi>6</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=n>conv2</span><span class=o>.</span><span class=n>weight</span> <span class=n>torch</span><span class=o>.</span><span class=n>Size</span><span class=p>([</span><span class=mi>16</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>5</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=n>conv2</span><span class=o>.</span><span class=n>bias</span> <span class=n>torch</span><span class=o>.</span><span class=n>Size</span><span class=p>([</span><span class=mi>16</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=n>fc1</span><span class=o>.</span><span class=n>weight</span> <span class=n>torch</span><span class=o>.</span><span class=n>Size</span><span class=p>([</span><span class=mi>120</span><span class=p>,</span> <span class=mi>256</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=n>fc1</span><span class=o>.</span><span class=n>bias</span> <span class=n>torch</span><span class=o>.</span><span class=n>Size</span><span class=p>([</span><span class=mi>120</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=n>fc2</span><span class=o>.</span><span class=n>weight</span> <span class=n>torch</span><span class=o>.</span><span class=n>Size</span><span class=p>([</span><span class=mi>84</span><span class=p>,</span> <span class=mi>120</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=n>fc2</span><span class=o>.</span><span class=n>bias</span> <span class=n>torch</span><span class=o>.</span><span class=n>Size</span><span class=p>([</span><span class=mi>84</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=n>fc3</span><span class=o>.</span><span class=n>weight</span> <span class=n>torch</span><span class=o>.</span><span class=n>Size</span><span class=p>([</span><span class=mi>62</span><span class=p>,</span> <span class=mi>84</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=n>fc3</span><span class=o>.</span><span class=n>bias</span> <span class=n>torch</span><span class=o>.</span><span class=n>Size</span><span class=p>([</span><span class=mi>62</span><span class=p>])</span>
</span></span></code></pre></td></tr></table></div></div><p>​<img src=https://raw.githubusercontent.com/Wh1teJ0ker/PicGo/main/Pic/net-img-1721377226926-61947a10-5f32-44d0-9b1b-82fb0894943e-20240823213840-ya193as.png alt=1721377226926-61947a10-5f32-44d0-9b1b-82fb0894943e>​</p><p>并且呢，我们再将npy进行可视化一下，明显是手写数字+字母</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>rows</span> <span class=o>=</span> <span class=mi>7</span>  <span class=c1># 7行</span>
</span></span><span class=line><span class=cl><span class=n>cols</span> <span class=o>=</span> <span class=mi>8</span>  <span class=c1># 8列</span>
</span></span><span class=line><span class=cl><span class=n>fig</span><span class=p>,</span> <span class=n>axes</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span><span class=n>rows</span><span class=p>,</span> <span class=n>cols</span><span class=p>,</span> <span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>20</span><span class=p>,</span> <span class=mi>20</span><span class=p>))</span> 
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>56</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>depthmap</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;./flag/</span><span class=si>{</span><span class=n>i</span><span class=si>}</span><span class=s1>.npy&#39;</span><span class=p>)</span>  <span class=c1># 使用numpy载入npy文件</span>
</span></span><span class=line><span class=cl>    <span class=n>ax</span> <span class=o>=</span> <span class=n>axes</span><span class=p>[</span><span class=n>i</span> <span class=o>//</span> <span class=n>cols</span><span class=p>,</span> <span class=n>i</span> <span class=o>%</span> <span class=n>cols</span><span class=p>]</span>  <span class=c1># 确定当前子图位置</span>
</span></span><span class=line><span class=cl>    <span class=n>im</span> <span class=o>=</span> <span class=n>ax</span><span class=o>.</span><span class=n>imshow</span><span class=p>(</span><span class=n>depthmap</span><span class=p>,</span> <span class=n>cmap</span><span class=o>=</span><span class=s1>&#39;viridis&#39;</span><span class=p>)</span>  
</span></span><span class=line><span class=cl>    <span class=n>ax</span><span class=o>.</span><span class=n>set_title</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39; </span><span class=si>{</span><span class=n>i</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>  <span class=c1>#</span>
</span></span><span class=line><span class=cl>    <span class=n>ax</span><span class=o>.</span><span class=n>axis</span><span class=p>(</span><span class=s1>&#39;off&#39;</span><span class=p>)</span>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>fig</span><span class=o>.</span><span class=n>colorbar</span><span class=p>(</span><span class=n>im</span><span class=p>,</span> <span class=n>ax</span><span class=o>=</span><span class=n>axes</span><span class=p>,</span> <span class=n>orientation</span><span class=o>=</span><span class=s1>&#39;vertical&#39;</span><span class=p>,</span> <span class=n>fraction</span><span class=o>=</span><span class=mf>0.02</span><span class=p>,</span> <span class=n>pad</span><span class=o>=</span><span class=mf>0.04</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>tight_layout</span><span class=p>()</span> 
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>savefig</span><span class=p>(</span><span class=s1>&#39;./pic/all.jpg&#39;</span><span class=p>)</span>  
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>  
</span></span></code></pre></td></tr></table></div></div><p>​<img src=https://raw.githubusercontent.com/Wh1teJ0ker/PicGo/main/Pic/net-img-1721379099634-423e4a2f-c263-42bd-9b52-a07d0df7f3b1-20240823213840-862r8kb.jpeg alt=1721379099634-423e4a2f-c263-42bd-9b52-a07d0df7f3b1>​</p><p>这边是给出了相关两个方式都可以查看出存在两个卷积层和三个全连接层，并且给出了其中的基本参数，我们需要去对比一下跟标准的LeNet模型有什么区别，或者说还缺少什么。</p><p>​<img src=https://raw.githubusercontent.com/Wh1teJ0ker/PicGo/main/Pic/net-img-1721377670885-161a6d8b-9275-4302-97da-5e1789a0f4cb-20240823213841-jc7zvwr.png alt=1721377670885-161a6d8b-9275-4302-97da-5e1789a0f4cb>​</p><p>我们发现在经典的LeNet模型，可以发现每次卷积后会进行池化，此处池化我们进行简单化考虑，采用最大池化，因此重点是考虑关于激活函数的问题。</p><p>（PS：实际在LeNet网络中，通常使用Sigmoid或Tanh激活函数在全连接层中，而在卷积层中可能使用Sigmoid、Tanh、ReLU等）</p><p>我们这里通过实际对模型的逆向查看，发现存在的仅有ReLU函数和Sigmoid函数（PS：如何逆向，010硬看，能搜索到）</p><p>需要使用到激活函数的一共有四个位置，卷积层或者全连接层的连接处，上面说明了一共两个卷积层，三个全连接层，因此需要使用到的是四个激活函数，卷积层需要搭配池化。</p><p>因此最终的可能性一共在<img src=https://raw.githubusercontent.com/Wh1teJ0ker/PicGo/main/Pic/net-img-9a6ae6806802df17bbd9b1662ec5b38d-20240823213841-4ohim9c.svg alt=9a6ae6806802df17bbd9b1662ec5b38d>为16种情况。</p><p>此外，还要注意在识别后需要对标签进行映射得到最终的FLAG</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span><span class=lnt>52
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.nn</span> <span class=k>as</span> <span class=nn>nn</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>json</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=n>pt</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=s2>&#34;./MyLeNet.pt&#34;</span><span class=p>,</span> <span class=n>map_location</span><span class=o>=</span><span class=s2>&#34;cpu&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>LeNet</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>(</span><span class=n>LeNet</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>conv1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=n>in_channels</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>out_channels</span><span class=o>=</span><span class=mi>6</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>maxpool1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>MaxPool2d</span><span class=p>(</span><span class=n>kernel_size</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>conv2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=n>in_channels</span><span class=o>=</span><span class=mi>6</span><span class=p>,</span> <span class=n>out_channels</span><span class=o>=</span><span class=mi>16</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>maxpool2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>MaxPool2d</span><span class=p>(</span><span class=n>kernel_size</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>fc1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>256</span><span class=p>,</span> <span class=mi>120</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>fc2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>120</span><span class=p>,</span> <span class=mi>84</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>fc3</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>84</span><span class=p>,</span> <span class=mi>62</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>conv1</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>maxpool1</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sigmoid</span><span class=p>()(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>conv2</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>maxpool2</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>()(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>flatten</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>start_dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>fc1</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sigmoid</span><span class=p>()(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>fc2</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>()(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>fc3</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>x</span>
</span></span><span class=line><span class=cl><span class=c1># 创建LeNet实例</span>
</span></span><span class=line><span class=cl><span class=n>lenet_model</span> <span class=o>=</span> <span class=n>LeNet</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>lenet_model</span><span class=o>.</span><span class=n>load_state_dict</span><span class=p>(</span><span class=n>pt</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=s1>&#39;./label.json&#39;</span><span class=p>,</span> <span class=s1>&#39;r&#39;</span><span class=p>)</span> <span class=k>as</span> <span class=n>json_file</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>label_mapping</span> <span class=o>=</span> <span class=n>json</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=n>json_file</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>reverse_label_mapping</span> <span class=o>=</span> <span class=p>{</span><span class=n>v</span><span class=p>:</span> <span class=n>k</span> <span class=k>for</span> <span class=n>k</span><span class=p>,</span> <span class=n>v</span> <span class=ow>in</span> <span class=n>label_mapping</span><span class=o>.</span><span class=n>items</span><span class=p>()}</span>
</span></span><span class=line><span class=cl><span class=c1># 获取所有标签</span>
</span></span><span class=line><span class=cl><span class=n>chars</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=n>reverse_label_mapping</span><span class=o>.</span><span class=n>values</span><span class=p>())</span>
</span></span><span class=line><span class=cl><span class=n>predicted_chars</span> <span class=o>=</span> <span class=p>[]</span>  <span class=c1># 用于保存所有的预测字符</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>56</span><span class=p>):</span>  <span class=c1># 从0到56</span>
</span></span><span class=line><span class=cl>    <span class=n>npy_file_path</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&#34;./flag/</span><span class=si>{</span><span class=n>i</span><span class=si>}</span><span class=s2>.npy&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>npy_data</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=n>npy_file_path</span><span class=p>)</span><span class=o>.</span><span class=n>reshape</span><span class=p>((</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>28</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>torch_input</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>(</span><span class=n>npy_data</span><span class=p>)</span><span class=o>.</span><span class=n>float</span><span class=p>()</span>  <span class=c1># 转换为PyTorch张量</span>
</span></span><span class=line><span class=cl>    <span class=c1># 使用LeNet模型进行推理</span>
</span></span><span class=line><span class=cl>    <span class=n>output</span> <span class=o>=</span> <span class=n>lenet_model</span><span class=p>(</span><span class=n>torch_input</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>predicted_index</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>output</span><span class=p>,</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>predicted_char</span> <span class=o>=</span> <span class=n>chars</span><span class=p>[</span><span class=n>predicted_index</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Prediction for </span><span class=si>{</span><span class=n>npy_file_path</span><span class=si>}</span><span class=s2>: </span><span class=si>{</span><span class=n>predicted_char</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>predicted_chars</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>predicted_char</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>result_string</span> <span class=o>=</span> <span class=s1>&#39;&#39;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>predicted_chars</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Concatenated Result:&#34;</span><span class=p>,</span> <span class=n>result_string</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h2 id=2021l3hctf-deepdarkfantasy>2021L3HCTF-DeepDarkFantasy</h2><p>直接打开encrypted.pth</p><p>先进行异或，KEY为0xde</p><p>​<img src=https://raw.githubusercontent.com/Wh1teJ0ker/PicGo/main/Pic/net-img-1721382769696-7366fcbc-845d-4294-8f7c-28e8e48fb513-20240823213841-be9zvih.png alt=1721382769696-7366fcbc-845d-4294-8f7c-28e8e48fb513>​</p><p>使用调试的方法逐步补全模型</p><p>​<img src=https://raw.githubusercontent.com/Wh1teJ0ker/PicGo/main/Pic/net-img-1721383234171-2f363bf4-0882-42b1-afdc-50f81bd42956-20240823213841-ltuv5rp.png alt=1721383234171-2f363bf4-0882-42b1-afdc-50f81bd42956>​</p><h1 id=白盒测试-模型的逆向工程>白盒测试-模型的逆向工程</h1><p>纯粹的模型逆向，先来分析一下初始代码</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.nn</span> <span class=k>as</span> <span class=nn>nn</span>
</span></span><span class=line><span class=cl><span class=n>flag</span><span class=o>=</span><span class=s1>&#39;&#39;</span>
</span></span><span class=line><span class=cl><span class=n>flag_list</span><span class=o>=</span><span class=p>[]</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=n>flag</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>flag_list</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=nb>ord</span><span class=p>(</span><span class=n>i</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=nb>input</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>(</span><span class=n>flag_list</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>float32</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>n</span><span class=o>=</span><span class=nb>len</span><span class=p>(</span><span class=nb>input</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>Net</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>(</span><span class=n>Net</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>linear</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>n</span><span class=p>,</span> <span class=n>n</span><span class=o>*</span><span class=n>n</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>conv</span><span class=o>=</span><span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>2</span><span class=p>),</span> <span class=n>stride</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span><span class=n>padding</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>linear</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=n>n</span><span class=p>,</span> <span class=n>n</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>conv</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>x</span>
</span></span><span class=line><span class=cl><span class=n>mynet</span><span class=o>=</span><span class=n>Net</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>mynet</span><span class=o>.</span><span class=n>load_state_dict</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=s1>&#39;model.pth&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>output</span><span class=o>=</span><span class=n>mynet</span><span class=p>(</span><span class=nb>input</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=s1>&#39;ciphertext.txt&#39;</span><span class=p>,</span> <span class=s1>&#39;w&#39;</span><span class=p>)</span> <span class=k>as</span> <span class=n>f</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>tensor</span> <span class=ow>in</span> <span class=n>output</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>channel</span> <span class=ow>in</span> <span class=n>tensor</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>for</span> <span class=n>row</span> <span class=ow>in</span> <span class=n>channel</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>f</span><span class=o>.</span><span class=n>write</span><span class=p>(</span><span class=s1>&#39; &#39;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=nb>map</span><span class=p>(</span><span class=nb>str</span><span class=p>,</span> <span class=n>row</span><span class=o>.</span><span class=n>tolist</span><span class=p>())))</span>
</span></span><span class=line><span class=cl>                <span class=n>f</span><span class=o>.</span><span class=n>write</span><span class=p>(</span><span class=s1>&#39;</span><span class=se>\n</span><span class=s1>&#39;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>将字符串转换为ascii码后化为向量，利用一个神经网络，主要是包含全连接层和卷积层，将向量输出。</p><p>关于这个网络，我们打印出模型数据，详细过程如下：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=n>pt</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=s2>&#34;./model.pth&#34;</span><span class=p>,</span> <span class=n>map_location</span><span class=o>=</span><span class=s2>&#34;cpu&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=n>pt</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>i</span><span class=p>,</span><span class=n>pt</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#linear.weight torch.Size([2209, 47])</span>
</span></span><span class=line><span class=cl><span class=c1>#linear.bias torch.Size([2209])</span>
</span></span><span class=line><span class=cl><span class=c1>#conv.weight torch.Size([1, 1, 2, 2])</span>
</span></span><span class=line><span class=cl><span class=c1>#conv.bias torch.Size([1])</span>
</span></span></code></pre></td></tr></table></div></div><ul><li><strong>输入处理</strong>：</li><li>输入是一个长度为 <code>47</code>​ 的向量。</li><li>通过线性层变换为一个长度为 <code>2209</code>​ 的向量。</li><li><strong>重塑张量</strong>：</li><li>将长度为 <code>2209</code>​ 的向量重塑为 <code>[1, 1, 47, 47]</code>​ 的四维张量。</li><li><strong>卷积操作</strong>：</li><li>卷积层应用一个 <code>2x2</code>​ 的卷积核，保持输出形状为 <code>[1, 1, 47, 47]</code>​。</li></ul><p>同时，我们看到这里存在有n的未知参数，上述我们已经通过读取模型方式获取到n的初始值为47</p><p>因此本题的重点也就是放在卷积层和全连接层的逆向操作</p><p>卷积层的逆向取决于nn.Conv2d的操作，核心思想是将外围补零后进行逆向操作</p><h1 id=other>Other</h1><p>其他的就是一些对抗生成模型，算是一个非常热门的考点，或者一些基于论文的AI模型安全问题，目前来说，这个方向资料相对比较少，也没有一个成熟的体系化建设，更多的需要继续去发掘。</p></section><div class=comments><script>const getTheme=window.localStorage&&window.localStorage.getItem("theme");let theme=getTheme==="dark"?"dark":"light",s=document.createElement("script");s.src="https://giscus.app/client.js",s.setAttribute("data-repo","Wh1teJ0ker/discussion"),s.setAttribute("data-repo-id","R_kgDOOTzcZA"),s.setAttribute("data-category","Announcements"),s.setAttribute("data-category-id","DIC_kwDOOTzcZM4CoxXV"),s.setAttribute("data-mapping","pathname"),s.setAttribute("data-strict","0"),s.setAttribute("data-reactions-enabled","1"),s.setAttribute("data-emit-metadata","0"),s.setAttribute("data-input-position","top"),s.setAttribute("data-theme",theme),s.setAttribute("data-lang","zh-CN"),s.setAttribute("data-loading","lazy"),s.setAttribute("crossorigin","anonymous"),s.setAttribute("async",""),document.querySelector("div.comments").innerHTML="",document.querySelector("div.comments").appendChild(s)</script></div><div class=paginator><a class=prev href=https://wh1tej0ker.github.io/post/2024-west-lake-sword-discussion-zskx3a.html><svg class="icon" width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M3.77086 21.1546C11.0491 22.698 21.4339 21.7773 21.4339 16.3608V4.63375c0-.69413-.075800000000001-1.3284-.2422-1.86588M3.77086 21.1546C1.9934 20.7777.973585 18.7264 1.08749 16.688c.17931-3.209.06972-7.25665-.08236-10.47293C.87809 3.52811 3.12891 1.16316 5.51029 1.25008c4.25565.15534 9.86671-.04779 13.28091-.24466 1.2952-.074686 2.0494.62843 2.4005 1.76245M3.77086 21.1546C4.56586 21.4723 5.49168 21.7879 6.5 22.0658M21.1917 2.76787c1.918 1.4143 1.9383 9.65123 1.7087 13.59293-2.0526 7.6586-10.5943 7.3054-16.4004 5.705M21.1917 2.76787C21.7612 4.51192 22.7203 9.67216 22 16.3608 21.2797 23.0494 11.3665 22.9511 6.5 22.0658M9.94496 9C9.28897 9.61644 7.63215 10.997 6.04814 11.7966 5.98257 11.8297 5.98456 11.9753 6.05061 12.0063c1.00435.4716 2.8788 1.9201 3.89435 2.9937M6.44444 11.9667C8.86549 12.0608 14 12 16 11" stroke="currentcolor" stroke-linecap="round"/></svg>
<span>2024西湖论剑</span></a>
<a class=next href=https://wh1tej0ker.github.io/post/2024-internet-of-vehicles-network-and-data-security-ctf-competition-z1vpry3.html><span>2024车联网网络和数据安全CTF竞赛</span><svg class="icon" width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M3.77086 21.1546C11.0491 22.698 21.4339 21.7773 21.4339 16.3608V4.63375c0-.69413-.075800000000001-1.3284-.2422-1.86588M3.77086 21.1546C1.9934 20.7777.973585 18.7264 1.08749 16.688c.17931-3.209.06972-7.25665-.08236-10.47293C.87809 3.52811 3.12891 1.16316 5.51029 1.25008c4.25565.15534 9.86671-.04779 13.28091-.24466 1.2952-.074686 2.0494.62843 2.4005 1.76245M3.77086 21.1546C4.56586 21.4723 5.49168 21.7879 6.5 22.0658M21.1917 2.76787c1.918 1.4143 1.9383 9.65123 1.7087 13.59293-2.0526 7.6586-10.5943 7.3054-16.4004 5.705M21.1917 2.76787C21.7612 4.51192 22.7203 9.67216 22 16.3608 21.2797 23.0494 11.3665 22.9511 6.5 22.0658M12.055 9C12.711 9.61644 14.3679 10.997 15.9519 11.7966 16.0174 11.8297 16.0154 11.9753 15.9494 12.0063 14.945 12.4779 13.0706 13.9264 12.055 15m3.5006-3.0333C13.1345 12.0608 8 12 6 11" stroke="currentcolor" stroke-linecap="round"/></svg></a></div></article></div><footer class=footer><p>&copy; 2025 <a href=https://wh1tej0ker.github.io/>Wh1teJ0kerのBlog</a>
Powered by
<a href=https://gohugo.io/ rel=noopener target=_blank>Hugo️️</a>
<a href=https://github.com/guangzhengli/hugo-theme-ladder rel=noopener target=_blank>Ladder</a>
️</p></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-up"><line x1="12" y1="19" x2="12" y2="5"/><polyline points="5 12 12 5 19 12"/></svg>
</a><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.querySelectorAll("pre > code").forEach(e=>{const s=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="Copy";function n(){t.innerHTML="Copied",setTimeout(()=>{t.innerHTML="Copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),n();return}const s=document.createRange();s.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(s);try{document.execCommand("copy"),n()}catch{}o.removeRange(s)}),e.parentNode.appendChild(t)})</script></main></body><script src=/main.min.cf83e1357eefb8bdf1542850d66d8007d620e4050b5715dc83f4a921d36ce9ce47d0d13c5d85f2b0ff8318d2877eec2f63b931bd47417a81a538327af927da3e.js integrity="sha512-z4PhNX7vuL3xVChQ1m2AB9Yg5AULVxXcg/SpIdNs6c5H0NE8XYXysP+DGNKHfuwvY7kxvUdBeoGlODJ6+SfaPg==" crossorigin=anonymous defer></script></html>